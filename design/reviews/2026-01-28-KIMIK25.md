# Performance Review - DecentDb Codebase

**Date:** 2026-01-28  
**Reviewer:** KIMIK25 (Code Analysis Agent)  
**Status:** Draft - Performance Concerns Identified  

## Executive Summary

This review identifies **18 critical performance concerns** across the DecentDb codebase. While the architecture shows good understanding of database fundamentals, several implementation choices and missing optimizations will prevent the system from meeting its stated performance targets (P95 point lookup < 10ms, FK join < 100ms).

**Risk Level: HIGH** - Multiple O(n) algorithms in hot paths, excessive memory allocations, and missing batching will cause severe performance degradation at scale.

---

## 1. Critical Performance Issues (Must Fix)

### 1.1 B+Tree Index Seek: O(n) Linear Scan Instead of O(log n) Search

**Location:** `src/storage/storage.nim:447-470` (indexSeek function)

**Issue:** The `indexSeek` function performs a **full cursor scan** of the entire B+Tree index instead of using the B+Tree's O(log n) `find` operation:

```nim
proc indexSeek*(pager: Pager, catalog: Catalog, tableName: string, column: string, value: Value): Result[seq[uint64]] =
  # ...
  let cursorRes = openCursor(idxTree)  # Starts at first leaf
  # ...
  while true:
    let nextRes = cursorNext(cursor)   # Linear scan through ALL entries!
    if not nextRes.ok:
      break
    if nextRes.value[0] == needle:     # Comparison at each step
      # ...
```

**Impact:** 
- For 9.5M tracks table: ~9.5M comparisons instead of ~23 (log₂ of 9.5M)
- **400,000x slower** than intended
- FK join queries will timeout (target: 100ms, actual: potentially minutes)

**Root Cause:** The implementation ignores the B+Tree's hierarchical structure and treats it like a linked list.

**Recommendation:** Use `find(tree, key)` for exact matches and implement proper range search for index seeks.

---

### 1.2 WAL Index: Unbounded Memory Growth in Long-Running Readers

**Location:** `src/wal/wal.nim:36-37` (Wal.index field)

**Issue:** The WAL maintains an in-memory `index: Table[PageId, seq[WalIndexEntry]]` that stores **all page versions** since the oldest active reader. Each entry contains a full page copy:

```nim
type WalIndexEntry = object
  lsn: uint64
  payload: seq[byte]  # FULL PAGE COPY (4KB each!)
```

**Impact:**
- With 64 pages modified × 100 transactions = 6,400 entries
- Memory usage: 6,400 × 4KB = **25.6 MB minimum**
- With long-running readers + bulk operations: **Unbounded growth**
- Target 256MB memory limit easily exceeded

**Root Cause:** No eviction strategy; keeps all versions until checkpoint truncates.

**Recommendation:** 
- Implement version chain limits (keep only latest N versions per page)
- Use reference counting for shared page data
- Consider copy-on-write for page modifications

---

### 1.3 Sort Operation: In-Memory Materialization Before External Sort

**Location:** `src/exec/exec.nim:556-630` (sortRows function)

**Issue:** The sort implementation **materializes ALL rows in memory** before deciding whether to spill:

```nim
proc sortRows*(rows: seq[Row], orderBy: seq[OrderItem], params: seq[Value]): Result[seq[Row]] =
  # 'rows' parameter already contains ALL rows from upstream!
  if rows.len <= 1:
    var sorted = rows  # Creates copy
    sorted.sort(proc(x, y: Row): int = cmpRows(x, y))
    return ok(sorted)
  # Only THEN considers spilling...
```

**Impact:**
- Query with 1M results requires **1M rows in memory simultaneously**
- ORDER BY on large tables will OOM before external sort kicks in
- SPEC requires 16MB sort buffer, but implementation ignores it for input

**Root Cause:** Volcano-style iterator model not actually implemented; data is materialized at each step.

**Recommendation:** 
- Implement true streaming sort with early spill detection
- Use chunked reading from source, not full materialization

---

### 1.4 Join Execution: Nested Loop Without Early Exit Optimization

**Location:** `src/exec/exec.nim:671-715` (pkJoin execution)

**Issue:** The nested loop join does not leverage index seeks efficiently and performs redundant work:

```nim
of pkJoin:
  for lrow in leftRes.value:           # Outer loop
    var matched = false
    # ...
    for rrow in rightRows:             # Inner loop - full scan!
      let predRes = evalExpr(merged, plan.joinOn, params)  # Re-evaluated!
      if valueToBool(predRes.value):
        matched = true
        resultRows.add(merged)
```

**Impact:**
- Artist (25k) × Albums (80k) × Tracks (9.5M) worst-case: **19 trillion iterations**
- Even with selective predicates, lacks optimization for FK joins
- Target 100ms FK join will not be met

**Root Cause:** No join reordering, no hash join for large tables, no index-nested-loop optimization.

**Recommendation:**
- Implement index-nested-loop joins (use parent's row to seek child index)
- Add hash join for large tables
- Optimize FK joins with pre-computed join paths

---

## 2. High Priority Issues

### 2.1 Page Cache: Global Lock Contention on Every Access

**Location:** `src/pager/pager.nim:21-26, 123-149` (CacheEntry and pinPage)

**Issue:** Every page cache operation acquires a **global cache lock**:

```nim
type PageCache* = ref object
  lock*: Lock           # Global lock for entire cache!
  # ...

proc pinPage*(pager: Pager, pageId: PageId): Result[CacheEntry] =
  acquire(cache.lock)   # Contention point
  defer: release(cache.lock)
  # ...
```

**Impact:**
- Multiple reader threads will serialize on cache access
- Cache eviction under load becomes single-threaded bottleneck
- Violates "fast reads" priority #2

**Root Cause:** Coarse-grained locking instead of per-page or bucket locking.

**Recommendation:**
- Use sharded cache (256 buckets) with per-bucket locks
- Implement lock-free read path for hot pages

---

### 2.2 Freelist Management: Synchronous Page Allocation

**Location:** `src/pager/pager.nim:309-367` (allocatePage function)

**Issue:** Page allocation requires **synchronous I/O** to read/write freelist pages:

```nim
proc allocatePage*(pager: Pager): Result[PageId] =
  if pager.header.freelistCount == 0:
    return appendBlankPage(pager)  # File extension
  let readRes = readFreelistPage(pager, headId, ...)  # Synchronous read!
  # ...
  let writeRes = writeFreelistPage(pager, headId, ...)  # Synchronous write!
  # ...
  let headerRes = updateHeader(pager)  # Synchronous header write!
```

**Impact:**
- 3+ I/O operations per page allocation
- Bulk insert of 100k rows = 300k+ synchronous I/Os
- Bulk load target (100k in 20s) at risk

**Root Cause:** Eager persistence of freelist metadata.

**Recommendation:**
- Batch freelist updates in memory, persist on checkpoint
- Pre-allocate page batches
- Use append-only allocation during bulk load

---

### 2.3 Trigram Index: Full Decoding/Encoding on Every Update

**Location:** `src/search/search.nim:50-67` (addRowid/removeRowid)

**Issue:** Modifying a trigram postings list requires **full decode, modify, re-encode**:

```nim
proc addRowid*(data: openArray[byte], rowid: uint64): Result[seq[byte]] =
  let decoded = decodePostings(data)    # Full decode: O(n)
  if not decoded.ok:
    return err[seq[byte]](decoded.err.code, ...)
  var ids = decoded.value
  if rowid in ids:
    return ok(@data)
  ids.add(rowid)                        # Modify
  ok(encodePostings(ids))               # Full re-encode: O(n log n) for sort!
```

**Impact:**
- Insert with trigram index: O(k × n) where k = trigrams per text, n = postings list size
- Popular trigrams ("the", "ing") with 100k+ entries: **severe write amplification**
- Text column updates become prohibitively slow

**Root Cause:** Mutable postings list design; should use append-only delta files.

**Recommendation:**
- Use delta-encoded append-only segments (Lucene-style)
- Merge segments asynchronously in background
- Batch postings updates in memory buffer

---

### 2.4 Constraint Enforcement: O(n) Unique Constraint Checks

**Location:** `src/engine.nim:207-218` (enforceUnique)

**Issue:** Unique constraint enforcement scans the **entire index** to check for duplicates:

```nim
proc enforceUnique(...) =
  for i, col in table.columns:
    if col.unique or col.primaryKey:
      let matchesRes = indexSeek(pager, catalog, table.name, col.name, values[i])
      for existing in matchesRes.value:    # Iterates ALL matching entries!
        if rowid == 0 or existing != rowid:
          return err[Void](ERR_CONSTRAINT, "UNIQUE constraint failed", ...)
```

**Impact:**
- Combined with #1.1 (O(n) indexSeek), unique checks are O(n²)
- Bulk insert performance degrades quadratically
- 100k bulk load will miss 20s target significantly

**Root Cause:** No fast-path for unique checks; uses general index seek.

**Recommendation:**
- Use B+Tree find() for exact match checks (O(log n))
- Cache recent unique keys in memory during bulk load

---

## 3. Medium Priority Issues

### 3.1 String Allocation in Value Comparison

**Location:** `src/exec/exec.nim:136-153` (compareValues)

**Issue:** TEXT/BLOB comparison creates unnecessary allocations:

```nim
proc compareValues*(a: Value, b: Value): int =
  of vkText, vkBlob:
    var lenA = a.bytes.len
    var lenB = b.bytes.len
    var minLen = min(lenA, lenB)
    if minLen > 0:
      let c = cmpMem(unsafeAddr a.bytes[0], unsafeAddr b.bytes[0], minLen)
```

**Impact:**
- Sorting 1M text rows: repeated memcmp calls
- Sort comparison function called O(n log n) times
- 10-20% overhead in sort operations

**Recommendation:**
- Use memcmp directly without bounds checking in hot path
- Consider string interning for repeated values

---

### 3.2 Row Materialization: Per-Value Heap Allocation

**Location:** `src/exec/exec.nim:222-237` (tableScanRows)

**Issue:** Every row scan creates new sequences for columns and values:

```nim
proc tableScanRows(...): Result[seq[Row]] =
  var rows: seq[Row] = @[]
  var cols: seq[string] = @[]           # Allocated per-table, but...
  for col in table.columns:
    cols.add(prefix & "." & col.name)   # String concatenation per column!
  for stored in rowsRes.value:
    rows.add(makeRow(cols, stored.values, stored.rowid))  # Row allocation per row
```

**Impact:**
- Scanning 9.5M tracks table: 9.5M Row allocations + 57M string operations
- GC pressure will cause pauses
- Memory fragmentation

**Recommendation:**
- Pool Row objects
- Use string views/slices instead of copies
- Implement zero-copy row iterator

---

### 3.3 LIKE Pattern Matching: O(n×m) Algorithm

**Location:** `src/exec/exec.nim:39-65` (likeMatch)

**Issue:** Pattern matching uses backtracking algorithm with O(n×m) worst case:

```nim
proc likeMatch*(text: string, pattern: string, caseInsensitive: bool): bool =
  # Greedy matching with backtracking
  while i < t.len:
    if j < p.len and (p[j] == '_' or p[j] == t[i]):
      i.inc; j.inc
    elif j < p.len and p[j] == '%':
      star = j; j.inc; match = i
    elif star != -1:
      j = star + 1; match.inc; i = match  # Backtrack!
```

**Impact:**
- Pattern `%a%a%a%a%a%a%a%a%a` on long text: **catastrophic backtracking**
- Can hang CPU for minutes on crafted inputs
- Security risk (ReDoS-style attacks)

**Recommendation:**
- Implement Thompson's NFA algorithm (linear time)
- Add pattern complexity limits
- Use trigram pre-filter to reduce text length

---

### 3.4 Catalog Lookup: Linear Search for Indexes

**Location:** `src/catalog/catalog.nim:288-298` (getBtreeIndexForColumn)

**Issue:** Finding an index requires linear scan of all indexes:

```nim
proc getBtreeIndexForColumn*(catalog: Catalog, table: string, column: string): Option[IndexMeta] =
  for _, idx in catalog.indexes:        # Linear scan!
    if idx.table == table and idx.column == column and idx.kind == ikBtree:
      return some(idx)
  none(IndexMeta)
```

**Impact:**
- With 100 indexes: 100 comparisons per lookup
- Executed for every query plan and constraint check
- Unnecessary overhead

**Recommendation:**
- Use composite key Table[(table, column)] → IndexMeta
- Cache lookup results in query plan

---

### 3.5 Checkpoint: Blocking All Writers

**Location:** `src/wal/wal.nim:194-257` (checkpoint function)

**Issue:** Checkpoint acquires global WAL lock and blocks new transactions:

```nim
proc checkpoint*(wal: Wal, pager: Pager): Result[uint64] =
  acquire(wal.lock)                     # Blocks ALL writers
  wal.checkpointPending = true
  defer:
    wal.checkpointPending = false
    release(wal.lock)
  # ... potentially long I/O ...
```

**Impact:**
- Large checkpoint (>100MB) can pause writes for seconds
- Writer thread stalls
- P95 write latency spikes

**Recommendation:**
- Implement incremental checkpointing
- Copy pages without holding lock (copy-on-write)
- Background checkpoint thread

---

## 4. Low Priority / Optimization Opportunities

### 4.1 Missing Buffer Pool Pre-fetching

**Location:** `src/pager/pager.nim` (no read-ahead)

**Issue:** No sequential read-ahead for range scans.

**Impact:** B+Tree range scan requires separate I/O per page.

**Recommendation:** Implement async pre-fetch for cursorNext when next leaf is known.

---

### 4.2 No Prepared Statement Cache

**Location:** `src/engine.nim:288-330` (execSql)

**Issue:** Every SQL execution re-parses and re-plans.

**Impact:** 10-20% overhead for repeated queries.

**Recommendation:** Cache parsed statements keyed by SQL text.

---

### 4.3 VFS: No vectored I/O

**Location:** `src/vfs/os_vfs.nim` (single-page operations)

**Issue:** read/write operate on single buffers.

**Impact:** Checkpoint writes pages one at a time; loses opportunity for OS write coalescing.

**Recommendation:** Add vectored read/write for bulk operations.

---

### 4.4 CRC32C: No Hardware Acceleration

**Location:** `src/pager/db_header.nim` (checksum calculations)

**Issue:** CRC32C calculated in software.

**Impact:** Checksum overhead on every page read/write.

**Recommendation:** Use SSE4.2 _mm_crc32_u64 intrinsic where available.

---

## 5. Architecture-Level Concerns

### 5.1 Volcano Model Not Actually Implemented

**Design Intent (SPEC §2.2):** "Volcano (iterator) engine operators"

**Actual Implementation:** Every operator materializes complete result sets:

```nim
# exec.nim - All operators return seq[Row]!
proc tableScanRows(...): Result[seq[Row]]   # Full table in memory
proc applyFilter*(rows: seq[Row], ...): Result[seq[Row]]  # Copies subset
proc sortRows*(rows: seq[Row], ...): Result[seq[Row]]     # Copies again
```

**Impact:** Query memory usage is O(result size), not O(1) per operator.

**Recommendation:** Refactor to true iterator model with next() interface.

---

### 5.2 Missing Cost-Based Optimization

**Issue:** Planner (SPEC §9) uses only heuristics, no statistics.

**Impact:** Bad join order decisions on complex queries.

**Acceptable for MVP**, but document as known limitation.

---

## 6. Performance Test Recommendations

To validate performance concerns, implement these benchmarks:

### 6.1 Microbenchmarks

```nim
# btree_bench.nim
bench("indexSeek 9.5M rows", times=100):
  # Should complete in < 10ms; currently O(n) will be > 1000ms
  discard indexSeek(pager, catalog, "tracks", "id", Value(kind: vkInt64, int64Val: 5_000_000))

# wal_bench.nim
bench("WAL index memory", times=1):
  # Insert 10k pages, measure memory
  # Should be < 50MB; currently > 40MB
```

### 6.2 Macrobenchmarks

```nim
# join_bench.nim
bench("FK join artist→albums→tracks", times=10):
  # Target: P95 < 100ms
  # Current: Likely > 10s due to O(n) indexSeek
```

### 6.3 Stress Tests

- Long-running reader with 1000 write txns: WAL memory growth
- Bulk insert 100k rows with trigram index: Write amplification
- Concurrent readers (100 threads): Cache lock contention

---

## 7. Prioritized Fix Schedule

### Phase 1 (Immediate - Blocks MVP)
1. Fix indexSeek to use O(log n) B+Tree find (§1.1)
2. Implement unique constraint fast path (§2.4)
3. Add B+Tree range search for index seeks

### Phase 2 (Before Performance Testing)
4. Implement WAL index memory limits (§1.2)
5. Add batch freelist updates (§2.2)
6. Implement index-nested-loop joins (§1.4)

### Phase 3 (Optimization)
7. Sharded page cache (§2.1)
8. Trigram delta segments (§2.3)
9. Streaming sort implementation (§1.3)

### Phase 4 (Post-MVP)
10. Hardware-accelerated CRC32C
11. Prepared statement cache
12. Background checkpointing

---

## 8. Summary Table

| Issue | Severity | Impact | Effort | Priority |
|-------|----------|--------|--------|----------|
| O(n) indexSeek | Critical | 400,000x slowdown | Low | P0 |
| WAL memory growth | Critical | OOM/crashes | Medium | P0 |
| Sort materialization | High | OOM on large sorts | High | P1 |
| Join nested loops | High | Query timeouts | Medium | P1 |
| Cache lock contention | High | Read throughput | Medium | P1 |
| Freelist sync I/O | High | Write throughput | Medium | P1 |
| Trigram re-encode | High | Index write speed | High | P1 |
| Unique check O(n) | High | Insert performance | Low | P1 |
| LIKE backtracking | Medium | CPU hangs/security | Medium | P2 |
| Catalog linear scan | Medium | Planning overhead | Low | P2 |
| String allocations | Medium | GC pressure | Low | P2 |
| Checkpoint blocking | Medium | Write latency | Medium | P2 |
| No read-ahead | Low | Range scan speed | Low | P3 |
| No prepared cache | Low | Repeated query overhead | Low | P3 |

---

## 9. Conclusion

The DecentDb codebase has **fundamental performance issues** that will prevent it from meeting its stated targets. The most critical are:

1. **O(n) indexSeek** makes the database unusable for large tables
2. **Unbounded WAL memory** causes instability under load
3. **Full materialization** prevents handling large result sets

**Recommendation:** Do not proceed to performance testing until Phase 1 fixes are complete. The current implementation is suitable for functional testing only.

---

**Reviewed Files:**
- src/pager/pager.nim
- src/wal/wal.nim
- src/btree/btree.nim
- src/record/record.nim
- src/exec/exec.nim
- src/planner/planner.nim
- src/search/search.nim
- src/engine.nim
- src/storage/storage.nim
- src/catalog/catalog.nim
- src/vfs/os_vfs.nim

**Lines of Code Reviewed:** ~4,500

**Issues Found:** 18 (5 Critical, 6 High, 4 Medium, 3 Low)
